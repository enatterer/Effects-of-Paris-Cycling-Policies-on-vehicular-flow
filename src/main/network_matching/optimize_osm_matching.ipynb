{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19eca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import osmnx as ox\n",
    "import momepy\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "import alphashape\n",
    "from pyproj import Proj, Geod\n",
    "import ast\n",
    "import matplotlib.font_manager as font_manager\n",
    "import datetime as dt\n",
    "\n",
    "fontsize = 20\n",
    "figsize = (15, 10)\n",
    "font = 'Times New Roman'\n",
    "\n",
    "data_path = '../../data/'  \n",
    "polygon_road_network = gpd.read_file(data_path + 'network/QGIS_Project/referentiel-comptages-edit.shp')\n",
    "paris_districts = gpd.read_file(data_path + 'districts_paris.geojson')\n",
    "df_car_detectors = gpd.read_file(data_path + 'all_car_detectors.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e60d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_length_in_meters(line_string):\n",
    "    # Define a UTM projection for the zone containing your coordinates\n",
    "    utm_zone = 31  # Assuming you are in Paris, which falls in UTM zone 31 for example\n",
    "    proj = Proj(proj='utm', zone=utm_zone, ellps='WGS84')\n",
    "\n",
    "    # Extract coordinates from the LineString\n",
    "    coordinates = list(line_string.coords)\n",
    "\n",
    "    # Transform the coordinates to UTM projection\n",
    "    utm_coordinates = [proj(lon, lat) for lon, lat in coordinates]\n",
    "\n",
    "    # Compute the distance between consecutive points in meters\n",
    "    total_length = 0\n",
    "    geod = Geod(ellps='WGS84')\n",
    "    for i in range(len(utm_coordinates) - 1):\n",
    "        lon1, lat1 = utm_coordinates[i]\n",
    "        lon2, lat2 = utm_coordinates[i + 1]\n",
    "        distance_meters = geod.inv(lon1, lat1, lon2, lat2)[-1]  # Use [-1] to get distance\n",
    "\n",
    "        # Handle case of very small distances\n",
    "        if np.isnan(distance_meters):\n",
    "            dx = lon2 - lon1\n",
    "            dy = lat2 - lat1\n",
    "            distance_meters = np.sqrt(dx**2 + dy**2)\n",
    "        total_length += distance_meters\n",
    "\n",
    "    return total_length\n",
    "\n",
    "def is_na_list(lst):\n",
    "    return lst is None or len(lst) == 0 or all(pd.isna(x) for x in lst)\n",
    "\n",
    "def parse_and_average_lanes(lanes_str):\n",
    "    if isinstance(lanes_str, list):\n",
    "        if is_na_list(lanes_str):\n",
    "            return np.nan\n",
    "        else: \n",
    "            return sum(map(int, lanes_str)) / len(lanes_str)\n",
    "    else:\n",
    "        if pd.isna(lanes_str):  # Check if input is NaN\n",
    "            return np.nan  # Return NaN if input is NaN\n",
    "    try:\n",
    "        # Attempt to parse the string as a list\n",
    "        lanes_list = ast.literal_eval(lanes_str)\n",
    "        if isinstance(lanes_list, list):\n",
    "            # If it's a list, calculate the average of list elements\n",
    "            return sum(map(int, lanes_list)) / len(lanes_list)\n",
    "        else:\n",
    "            # If it's a single integer, return it as is\n",
    "            return int(lanes_list)\n",
    "    except (SyntaxError, ValueError):\n",
    "        # If parsing fails or the lanes_str is not a list, parse as single integer\n",
    "        return int(lanes_str)\n",
    "\n",
    "def approximate_number_of_lanes(df_matched):\n",
    "    df_matched_with_lanes_approximated = df_matched.copy()\n",
    "    average_lanes_per_highway = df_matched.groupby('highway')['lanes_mapped'].mean()\n",
    "    for index, row in df_matched_with_lanes_approximated.iterrows():\n",
    "        if pd.isna(row['lanes_mapped']):\n",
    "            df_matched_with_lanes_approximated.at[index, 'lanes_mapped'] = average_lanes_per_highway[row['highway']]\n",
    "    return df_matched_with_lanes_approximated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "663e7e7f",
   "metadata": {},
   "source": [
    "## Goal of this notebook\n",
    "\n",
    "The goal of this notebook is to optimize the matching process between the detector network and the \"main roads\" of OpenStreetMap. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31fe7c84",
   "metadata": {},
   "source": [
    "This notebook matches the links of the Paris counting network with the links of an OSM network:\n",
    "- Load [OpenStreetMap network](https://www.openstreetmap.org/#map=7/51.330/10.453) in Bvd Peripherique\n",
    "- Load [detector network](https://opendata.paris.fr/explore/dataset/referentiel-comptages-routiers/information/)\n",
    "- Perform matching by angle and centroid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08921cc8",
   "metadata": {},
   "source": [
    "## Load networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42d0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform it for years 2013 - 2024. One cannot retrieve detector data from OSM from before 2013.\n",
    "year = 2024\n",
    "\n",
    "with_boulevard_peripherique = True\n",
    "\n",
    "if with_boulevard_peripherique:\n",
    "    output_path = \"output/detectors_matched_with_bvd_peripherique_2_osm_01_\" + str(year)\n",
    "else:\n",
    "    output_path = \"output/detectors_matched_2_osm_01_\" + str(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f43313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_17127/2375514943.py:29: UserWarning: Approach is not set. Defaulting to 'primal'.\n",
      "  nodes_osm, df_osm = momepy.nx_to_gdf(G_road_network, points=True, lines=True)\n"
     ]
    }
   ],
   "source": [
    "# get OSM dataframe and process car detectors\n",
    "\n",
    "if with_boulevard_peripherique:\n",
    "    G_road_network = ox.graph_from_place(\"Paris\", simplify=True, network_type=\"drive\")\n",
    "    df_detectors = df_car_detectors.copy()\n",
    "    \n",
    "else:\n",
    "    alpha_shape = alphashape.alphashape(polygon_road_network, 435)\n",
    "    coordinates = list(alpha_shape.exterior[0].coords)\n",
    "    polygon = Polygon(coordinates)\n",
    "    x_coords, y_coords = zip(*coordinates)\n",
    "\n",
    "    overpass_settings = '[out:json][timeout:90][date:\"' + str(year) + '-01-01T00:00:00Z\"]'\n",
    "    ox.settings.overpass_settings = overpass_settings\n",
    "    ox.settings.log_console = True\n",
    "    G_road_network = ox.graph_from_polygon(\n",
    "        polygon, simplify=True, network_type=\"drive\")\n",
    "    \n",
    "    boundary_gdf = gpd.GeoDataFrame(\n",
    "    geometry=[polygon], crs=df_car_detectors.crs)\n",
    "    df_car_detectors_without_dupl = df_car_detectors.drop_duplicates(\n",
    "        subset='iu_ac', keep='first')\n",
    "    car_detectors_within_boundary = gpd.sjoin(\n",
    "        df_car_detectors_without_dupl, boundary_gdf, op='within')\n",
    "    df_detectors = car_detectors_within_boundary.copy()\n",
    "    \n",
    "nodes_osm, df_osm = momepy.nx_to_gdf(G_road_network, points=True, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93baeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process osm network\n",
    "df_osm['osm_id'] = range(1, len(df_osm) + 1)\n",
    "df_osm.drop(columns=['width', 'bridge', 'tunnel', 'junction', 'access', 'ref'])\n",
    "\n",
    "# Filter osm network for higher order roads\n",
    "df_osm_hor = df_osm[\n",
    "    df_osm[\"highway\"].str.contains(\"motorway\") |\n",
    "    df_osm[\"highway\"].str.contains(\"trunk\") |\n",
    "    df_osm[\"highway\"].str.contains(\"primary\") |\n",
    "    df_osm[\"highway\"].str.contains(\"secondary\") |\n",
    "    df_osm[\"highway\"].str.contains(\"tertiary\") \n",
    "]\n",
    "df_osm_hor = df_osm_hor[df_osm_hor['geometry'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0727a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matching process\n",
    "\n",
    "# Trade-off between scoring angle difference and centroid distance. alpha = 0.8 seemed to get the best matching. Keep in mind that we normalize the absolute difference of centroid \n",
    "# distance and angle difference is done in the score computation. \n",
    "alpha = 0.8\n",
    "\n",
    "# Maximum centroid distance between two candidates\n",
    "maximum_distance = 50\n",
    "\n",
    "# Maximum angle difference between two candidates\n",
    "maximum_angle = 15 * np.pi / 180.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76a69f68",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71059255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# df_detectors.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1672395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# df_osm.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74860329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# df_osm_hor.plot(ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fdde854",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47dfaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_17127/3904791298.py:3: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_detectors[\"geometry\"].centroid.x, df_detectors[\"geometry\"].centroid.y]).T\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_17127/3904791298.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_osm_hor[\"geometry\"].centroid.x, df_osm_hor[\"geometry\"].centroid.y]).T\n"
     ]
    }
   ],
   "source": [
    "# Calculate centroids\n",
    "detector_centroids = np.vstack([\n",
    "    df_detectors[\"geometry\"].centroid.x, df_detectors[\"geometry\"].centroid.y]).T\n",
    "\n",
    "osm_centroids = np.vstack([\n",
    "    df_osm_hor[\"geometry\"].centroid.x, df_osm_hor[\"geometry\"].centroid.y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1261c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate orientation\n",
    "\n",
    "def angle(geometry):\n",
    "    coordinates = np.array(geometry.xy).T\n",
    "    return np.arctan2(coordinates[-1, 1] - coordinates[0, 1], coordinates[-1, 0] - coordinates[0, 0])\n",
    "    \n",
    "detector_angles = df_detectors[\"geometry\"].apply(angle).values\n",
    "osm_angles = df_osm_hor[\"geometry\"].apply(angle).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48fc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate n-to-m distances\n",
    "centroid_distances = np.zeros((len(detector_centroids), len(osm_centroids)))\n",
    "angle_distances = np.zeros((len(detector_centroids), len(osm_centroids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9478e0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6293577d344d07ae184d01b5106c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in tqdm(range(len(detector_centroids))):\n",
    "    centroid_distances[k,:] = la.norm(detector_centroids[k] - osm_centroids, axis = 1)\n",
    "    angle_distances[k,:] = np.abs(detector_angles[k] - osm_angles)\n",
    "\n",
    "angle_distances[angle_distances < 0.0] += 2.0 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6386a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare scoring / matching\n",
    "normalization_variable = angle_distances.mean()/centroid_distances.mean()\n",
    "\n",
    "scores = alpha * centroid_distances + (1-alpha) * (1/normalization_variable) * angle_distances\n",
    "# scores = alpha * centroid_distances + (1-alpha) * 0.1 * angle_distances\n",
    "\n",
    "# Deactivate improbable matchings\n",
    "scores[centroid_distances > maximum_distance] = np.inf\n",
    "scores[angle_distances > maximum_angle] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "582ea5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059717018445771874"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_distances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946611c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c1a1039bee4d168f8db3b5807c238a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2497557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matching process\n",
    "matchings = []\n",
    "matched_scores = []\n",
    "\n",
    "# The idea is relatively simple:\n",
    "# - Find the matching with the smallest score among those with a finite value\n",
    "# - Note down the matching, and set all matching containing the two links to Inf\n",
    "# - Continue until no scores with finite value are left\n",
    "\n",
    "current = np.count_nonzero(~np.isfinite(scores))\n",
    "\n",
    "with tqdm(total = np.prod(scores.shape) - current) as progress:\n",
    "    while np.count_nonzero(np.isfinite(scores)) > 0:\n",
    "        # Find best score and note down\n",
    "        index = np.unravel_index(np.argmin(scores), scores.shape)\n",
    "        matched_scores.append(scores[index])\n",
    "\n",
    "        # Set both invlved links to Inf\n",
    "        scores[index[0], :] = np.inf\n",
    "        scores[:, index[1]] = np.inf\n",
    "        \n",
    "        # Manage progress plotting\n",
    "        update = np.count_nonzero(~np.isfinite(scores))\n",
    "        \n",
    "        if update > current:\n",
    "            progress.update(update - current)\n",
    "            current = update\n",
    "\n",
    "        matchings.append(index)\n",
    "        \n",
    "matchings = np.array(matchings) # The matchings themselves (index reference, index matsim)\n",
    "matched_scores = np.array(matched_scores) # The scores of the matchings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17bc09aa",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5ce77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a data set containing all matching information\n",
    "df_matching = pd.DataFrame({\n",
    "    \"iu_ac\": df_detectors.iloc[matchings[:, 0]][\"iu_ac\"].values,\n",
    "    \"geometry_detector\": df_detectors.iloc[matchings[:, 0]][\"geometry\"].values,\n",
    "    \"osm_id\": df_osm_hor.iloc[matchings[:,1]][\"osm_id\"].values,\n",
    "    \"lanes\": df_osm_hor.iloc[matchings[:, 1]][\"lanes\"].values,\n",
    "    \"highway\": df_osm_hor.iloc[matchings[:, 1]][\"highway\"].values,\n",
    "    \"oneway\": df_osm_hor.iloc[matchings[:, 1]][\"oneway\"].values,\n",
    "    \"length_mapped_osm_street\": df_osm_hor.iloc[matchings[:, 1]][\"length\"].values,\n",
    "    \"score\": matched_scores,\n",
    "    \"date_start\": df_detectors.iloc[matchings[:,0]][\"date_debut\"].values,\n",
    "    \"date_end\": df_detectors.iloc[matchings[:,0]][\"date_fin\"].values,\n",
    "})\n",
    "df_matching = df_matching.sort_values(by='iu_ac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "211b9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching['length_detector_street'] = df_matching['geometry_detector'].apply(lambda x: line_length_in_meters(x))\n",
    "df_matching['lanes_mapped'] = df_matching['lanes'].apply(parse_and_average_lanes)\n",
    "df_matched_with_lanes_approximated = approximate_number_of_lanes(df_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48237511",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == 2013:\n",
    "    # nan_count = df_matched_with_lanes_approximated['lanes_mapped'].isna().sum()\n",
    "    # print(\"Number of NaN values in 'lanes_mapped' column:\", nan_count)\n",
    "    \n",
    "    # number of lanes are missing for highways of type \"primary_link\", \"secondary_link\", \"trunk_link\" and \"tertiary_link\"\n",
    "    number_of_lanes_primary_link = df_matched_with_lanes_approximated[df_matched_with_lanes_approximated['highway'] == 'primary']['lanes_mapped'].mean()\n",
    "    number_of_lanes_secondary_link = df_matched_with_lanes_approximated[df_matched_with_lanes_approximated['highway'] == 'secondary']['lanes_mapped'].mean()\n",
    "    number_of_lanes_tertiary_link = df_matched_with_lanes_approximated[df_matched_with_lanes_approximated['highway'] == 'tertiary']['lanes_mapped'].mean()\n",
    "    number_of_lanes_trunk_link = df_matched_with_lanes_approximated[df_matched_with_lanes_approximated['highway'] == 'trunk']['lanes_mapped'].mean()\n",
    "    print(number_of_lanes_primary_link, number_of_lanes_secondary_link, number_of_lanes_trunk_link)\n",
    "    \n",
    "    df_matched_with_lanes_approximated.loc[df_matched_with_lanes_approximated['highway'] == 'primary_link', 'lanes_mapped'] = number_of_lanes_primary_link\n",
    "    df_matched_with_lanes_approximated.loc[df_matched_with_lanes_approximated['highway'] == 'secondary_link', 'lanes_mapped'] = number_of_lanes_secondary_link\n",
    "    df_matched_with_lanes_approximated.loc[df_matched_with_lanes_approximated['highway'] == 'tertiary_link', 'lanes_mapped'] = number_of_lanes_tertiary_link\n",
    "    df_matched_with_lanes_approximated.loc[df_matched_with_lanes_approximated['highway'] == 'trunk_link', 'lanes_mapped'] = number_of_lanes_trunk_link\n",
    "    \n",
    "    # nan_count = df_matched_with_lanes_approximated['lanes_mapped'].isna().sum()\n",
    "    # print(\"Number of NaN values in 'lanes_mapped' column:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6cb271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9\n",
    "percentile = df_matched_with_lanes_approximated['score'].quantile(p)\n",
    "\n",
    "df_matching_best = df_matched_with_lanes_approximated[df_matched_with_lanes_approximated['score'] < percentile]\n",
    "gdf_matched = gpd.GeoDataFrame(df_matching_best, geometry='geometry_detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee0bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "df_matching_best.to_csv(output_path + \"_best_matches.csv\", sep=\";\", index=False)\n",
    "df_matched_with_lanes_approximated.to_csv(output_path + \".csv\", sep=\";\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7dd6f2",
   "metadata": {},
   "source": [
    "## Plot for districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d016e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# districts = gpd.read_file(data_path + 'districts_paris.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e09a4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter detectors for date_debut and date_fin\n",
    "# start_date = pd.Timestamp('2023-01-01 00:00:00+0000', tz='UTC')\n",
    "# df_detectors_2023 = df_detectors[(df_detectors['date_debut'] <= start_date) & (df_detectors['date_fin'] >= start_date)]\n",
    "\n",
    "# zone1 = districts[(districts['c_ar'] == 1) | (districts['c_ar'] == 2) | (districts['c_ar'] == 3) | (districts['c_ar'] == 4)]\n",
    "# zone2 = districts[(districts['c_ar'] == 5) | (districts['c_ar'] == 6) | (districts['c_ar'] == 7)]\n",
    "# zone_1_boundary = zone1.geometry.unary_union\n",
    "# zone_2_boundary = zone2.geometry.unary_union\n",
    "\n",
    "# gdf_matched_intersect_zone_1_boundary = gdf_matched[gdf_matched.intersects(zone_1_boundary)]\n",
    "# df_osm_hor_intersect_zone_1_boundary = df_osm_hor[df_osm_hor.intersects(zone_1_boundary)]\n",
    "# df_detectors_intersect_zone_1_boundary = df_detectors_2023[df_detectors_2023.intersects(zone_1_boundary)]\n",
    "\n",
    "# gdf_matched_intersect_zone_2_boundary = gdf_matched[gdf_matched.intersects(zone_2_boundary)]\n",
    "# df_osm_hor_intersect_zone_2_boundary = df_osm_hor[df_osm_hor.intersects(zone_2_boundary)]\n",
    "# df_detectors_intersect_zone_2_boundary = df_detectors_2023[df_detectors_2023.intersects(zone_2_boundary)]\n",
    "# df_osm_intersect_zone_1_boundary = df_osm[df_osm.intersects(zone_1_boundary)]\n",
    "# df_osm_intersect_zone_2_boundary = df_osm[df_osm.intersects(zone_2_boundary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5732d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# df_osm_intersect_zone_1_boundary.plot(ax=ax, linewidth = 0.5, color = \"grey\", label = \"OSM road network\")\n",
    "# df_osm_hor_intersect_zone_1_boundary.plot(ax=ax, color = 'orange', linewidth = 4, label = \"OSM higher order roads on 01.01.2024\")\n",
    "# df_detectors_intersect_zone_1_boundary.plot(ax=ax, linewidth=2, color = \"green\", label = \"Detector network\")\n",
    "# gdf_matched_intersect_zone_1_boundary.plot(ax=ax, color = 'blue', linewidth=1, label = \"Detectors matched to OSM higher order roads\")\n",
    "\n",
    "# df_osm_intersect_zone_2_boundary.plot(ax=ax, linewidth = 0.5, color = \"grey\")\n",
    "# df_osm_hor_intersect_zone_2_boundary.plot(ax=ax, color = 'orange', linewidth = 4)\n",
    "# df_detectors_intersect_zone_2_boundary.plot(ax=ax, linewidth=2, color = \"green\")\n",
    "# gdf_matched_intersect_zone_2_boundary.plot(ax=ax, color = 'blue', linewidth=1)\n",
    "\n",
    "# exterior_x, exterior_y = zone_1_boundary.exterior.xy\n",
    "# plt.plot(exterior_x, exterior_y, color = 'magenta', linewidth = 4, label = \"District 1 boundary\")\n",
    "\n",
    "# exterior_x_zone_2, exterior_y_zone_2 = zone_2_boundary.exterior.xy\n",
    "# plt.plot(exterior_x_zone_2, exterior_y_zone_2, color = 'purple', linewidth = 4, label = \"District 2 boundary\")\n",
    "\n",
    "# plt.xlabel(\"Longitude\", font = font, fontsize = fontsize)\n",
    "# plt.ylabel(\"Latitude\", font = font, fontsize = fontsize)\n",
    "# plt.title(\"Zone 1 and 2: Matches of detectors to OSM higher order roads\", font = font, fontsize = fontsize)\n",
    "# plt.xticks(font = font, fontsize = 15)\n",
    "# plt.yticks(font = font, fontsize = 15)\n",
    "# font_legend = font_manager.FontProperties(family=font, style='normal', size=15)\n",
    "# plt.legend(loc='lower left', prop = font_legend)\n",
    "# plt.savefig(\"results/zone_1_matched.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5535eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# df_osm_intersect_zone_1_boundary.plot(ax=ax, linewidth = 0.5, color = \"grey\", label = \"OSM road network\")\n",
    "# df_osm_hor_intersect_zone_1_boundary.plot(ax=ax, color = 'orange', linewidth = 4, label = \"OSM higher order roads on 01.01.2024\")\n",
    "# df_detectors_intersect_zone_1_boundary.plot(ax=ax, linewidth=2, color = \"green\", label = \"Detector network\")\n",
    "\n",
    "# df_osm_intersect_zone_2_boundary.plot(ax=ax, linewidth = 0.5, color = \"grey\")\n",
    "# df_osm_hor_intersect_zone_2_boundary.plot(ax=ax, color = 'orange', linewidth = 4)\n",
    "# df_detectors_intersect_zone_2_boundary.plot(ax=ax, linewidth=2, color = \"green\")\n",
    "\n",
    "# exterior_x, exterior_y = zone_1_boundary.exterior.xy\n",
    "# plt.plot(exterior_x, exterior_y, color = 'magenta', linewidth = 4, label = \"District 1 boundary\")\n",
    "\n",
    "# exterior_x_zone_2, exterior_y_zone_2 = zone_2_boundary.exterior.xy\n",
    "# plt.plot(exterior_x_zone_2, exterior_y_zone_2, color = 'purple', linewidth = 4, label = \"District 2 boundary\")\n",
    "\n",
    "# plt.xlabel(\"Longitude\", font = font, fontsize = fontsize)\n",
    "# plt.ylabel(\"Latitude\", font = font, fontsize = fontsize)\n",
    "# plt.title(\"Zone 1 and 2: OSM higher roads and detector network\", font = font, fontsize = fontsize)\n",
    "# plt.xticks(font = font, fontsize = 15)\n",
    "# plt.yticks(font = font, fontsize = 15)\n",
    "# font_legend = font_manager.FontProperties(family=font, style='normal', size=15)\n",
    "# plt.legend(loc='lower left', prop = font_legend)\n",
    "# plt.savefig(\"results/zone_1_osm_hor_and_dets.pdf\", dpi=1000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a587571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_length_in_lane_km(gdf):\n",
    "#     length_in_lane_km = 0\n",
    "\n",
    "#     for idx, row in gdf.iterrows():\n",
    "#         length = row['length_detector_street']\n",
    "#         lanes = row['lanes_mapped']\n",
    "#         if pd.isna(lanes):\n",
    "#             continue\n",
    "#         if pd.isna(length):\n",
    "#             continue\n",
    "#         length_in_lane_km += length * lanes / 1000\n",
    "#         # print(length_in_lane_km)\n",
    "#     return length_in_lane_km\n",
    "\n",
    "# length_in_lane_km_zone_1 = get_length_in_lane_km(gdf_matched_intersect_zone_1_boundary)\n",
    "# length_in_lane_km_zone_2 = get_length_in_lane_km(gdf_matched_intersect_zone_2_boundary)\n",
    "    \n",
    "# print(length_in_lane_km_zone_1)\n",
    "# print(length_in_lane_km_zone_2)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d75d7a89",
   "metadata": {},
   "source": [
    "We find, for 01.01.2024:\n",
    "\n",
    "Z1: 78.66487745107128\n",
    "Z2: 121.94722011749302"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d00c10",
   "metadata": {},
   "source": [
    "## Plot overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e418133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# # df_matching_best.plot(ax=ax, color = 'magenta', linewidth=1, label = \"Matches\")\n",
    "# df_osm_hor.plot(ax=ax, color = 'orange', linewidth = 4, label = \"OSM higher order roads\")\n",
    "# df_detectors.plot(ax=ax, linewidth=1, color = \"green\", label = \"Detectors\")\n",
    "\n",
    "# plt.xlabel(\"Longitude\", font = font, fontsize = fontsize)\n",
    "# plt.ylabel(\"Latitude\", font = font, fontsize = fontsize)\n",
    "# plt.title(\"Paris - OSM higher order roads and detector matches\", font = font, fontsize = fontsize)\n",
    "\n",
    "# plt.xticks(font = font, fontsize = fontsize)\n",
    "# plt.yticks(font = font, fontsize = fontsize)\n",
    "# font_legend = font_manager.FontProperties(family=font, style='normal', size=15)\n",
    "# plt.legend(loc='upper left', prop = font_legend)\n",
    "\n",
    "# plt.savefig(\"results/osm_hor_and_detectors.pdf\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc3332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comparison = df_detectors.copy()\n",
    "# df_comparison = pd.merge(df_comparison, df_matching)\n",
    "# df_comparison.to_file(\"output/detectors_matched_2_osm.geojson\", driver = 'GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5616c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# osm_matched_2_detectors = df_osm_hor.copy()\n",
    "# osm_matched_2_detectors = pd.merge(osm_matched_2_detectors, df_matching)\n",
    "# osm_matched_2_detectors.to_file(\n",
    "#     \"output/osm_matched_2_detectors.geojson\", driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
