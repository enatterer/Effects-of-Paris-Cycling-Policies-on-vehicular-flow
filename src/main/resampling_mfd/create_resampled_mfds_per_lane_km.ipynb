{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import momepy\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from shapely.geometry import Polygon\n",
    "import alphashape\n",
    "import osmnx as ox\n",
    "from shapely.wkt import loads\n",
    "\n",
    "data_path = '../../data/' \n",
    "paris_districts = gpd.read_file(data_path + 'districts_paris.geojson')\n",
    "df_car_detectors = gpd.read_file(data_path + 'all_car_detectors.geojson')\n",
    "matched_detectors_2013 = pd.read_csv('../network_matching/output/matches_2013.csv', sep=\";\")\n",
    "matched_detectors_2022 = pd.read_csv('../network_matching/output/matches_2022.csv', sep=\";\")\n",
    "best_matches_2013 = pd.read_csv('../network_matching/output/best_matches_2013.csv', sep=\";\")\n",
    "best_matches_2022 = pd.read_csv('../network_matching/output/best_matches_2022.csv', sep=\";\")\n",
    "qgis_road_network = gpd.read_file(data_path + 'network/QGIS_Project/referentiel-comptages-edit.shp')\n",
    "alpha_shape = alphashape.alphashape(qgis_road_network, 435)\n",
    "coordinates = list(alpha_shape.exterior[0].coords)\n",
    "polygon = Polygon(coordinates)\n",
    "\n",
    "resultpath = 'results/'\n",
    "\n",
    "def merge_districts(districts_to_merge:list):\n",
    "    districts_to_merge = paris_districts[paris_districts['c_ar'].isin(districts_to_merge)]\n",
    "    merged_districts = districts_to_merge.unary_union\n",
    "    merged = gpd.GeoDataFrame(geometry=[merged_districts], crs=paris_districts.crs)\n",
    "    return merged\n",
    "\n",
    "def read_detector_data():\n",
    "    ldd_2010_2012 = pd.read_csv(data_path + '/traffic_data/traffic_data_2010_2012.csv')\n",
    "    # ldd_2013_2020 = pd.read_csv(data_path + 'traffic_data.csv')\n",
    "    ldd_2021_2022 = pd.read_csv(data_path + '/traffic_data/traffic_data_2021_2022.csv')\n",
    "    ldd = pd.concat([ldd_2010_2012, ldd_2021_2022])\n",
    "    ldd['t_1h'] = pd.to_datetime(ldd['t_1h'])\n",
    "    ldd_2010 = ldd[ldd['t_1h'].dt.year == 2010]\n",
    "    ldd_2022 = ldd[ldd['t_1h'].dt.year == 2022]\n",
    "    return ldd_2010, ldd_2022\n",
    "\n",
    "\n",
    "class ResampledMFD():\n",
    "    def __init__(self, ldd, p_sample: float, n_combinations: int):\n",
    "        self.ldd = ldd\n",
    "        self.p_sample = p_sample\n",
    "        self.n_combinations = n_combinations\n",
    "\n",
    "    def compute_resampled_mfd(self):\n",
    "        self.resampled_mfd = ResampledMFD.resample_mfd(\n",
    "            self.ldd, self.p_sample, self.n_combinations)\n",
    "        resampled_mfd_envelope, capacity, critical_occupancy = ResampledMFD.get_resampled_mfd_envelope(\n",
    "            self.resampled_mfd)\n",
    "        self.resampled_mfd_envelope = resampled_mfd_envelope\n",
    "        self.capacity = capacity\n",
    "        self.critical_occupancy = critical_occupancy\n",
    "        return\n",
    "\n",
    "    def print_resampled_mfd(self):\n",
    "        print(self.capacity, self.critical_occupancy)\n",
    "\n",
    "    def resample_mfd(ldd, p_sample, n_combinations):\n",
    "        n_population = ldd.iu_ac.nunique()\n",
    "        n_samples = int(n_population * p_sample)\n",
    "\n",
    "        population = ldd.iu_ac.unique().tolist()\n",
    "        population_subsets = []\n",
    "        seen_subsets = set()\n",
    "\n",
    "        while len(population_subsets) < n_combinations:\n",
    "            subsets_indices = tuple(\n",
    "                sorted(sample_without_replacement(n_population, n_samples)))\n",
    "            if subsets_indices not in seen_subsets:\n",
    "                subset = [population[n] for n in subsets_indices]\n",
    "                population_subsets.append(subset)\n",
    "                seen_subsets.add(subsets_indices)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        subsets_mfds = []\n",
    "        for idx, subset in enumerate(population_subsets):\n",
    "            # print(idx/len(population_subsets))\n",
    "            subset_ldd = ldd.loc[ldd.iu_ac.isin(subset)]\n",
    "\n",
    "            mfd = []\n",
    "            for tsp, temp in subset_ldd.groupby('t_1h'):\n",
    "                time = (tsp - datetime.datetime.combine(tsp.date(),\n",
    "                        datetime.time.min)).total_seconds()\n",
    "                flow = temp.q_per_lane_km.mean()\n",
    "                occupancy = temp.k_per_lane_km.mean()\n",
    "                # TODO Hier normalisieren mit den Anzahl an Lanes und der Länge der Straße.\n",
    "                mfd.append((tsp, time, flow, occupancy))\n",
    "            mfd = pd.DataFrame(\n",
    "                mfd, columns=['tsp', 'time', 'flow', 'occupancy'])\n",
    "            subsets_mfds.append(mfd)\n",
    "\n",
    "        resampled_mfd = pd.concat(subsets_mfds)\n",
    "        return resampled_mfd\n",
    "\n",
    "\n",
    "    def get_resampled_mfd_envelope(resampled_mfd):\n",
    "        # choose the number of bins that best fits occupancy values\n",
    "        resampled_mfd['occupancy_bin'] = pd.cut(resampled_mfd['occupancy'],\n",
    "                                                bins=int(resampled_mfd['occupancy'].max()))\n",
    "        # taking the median of top M flow values per occupancy bin\n",
    "        resampled_mfd_envelope = []\n",
    "        for bin, temp in resampled_mfd.groupby('occupancy_bin', observed=True):\n",
    "            upper_flow = temp.nlargest(50, 'flow', 'all').flow.median()\n",
    "            occupancy = bin.mid\n",
    "            resampled_mfd_envelope.append((upper_flow, occupancy))\n",
    "        resampled_mfd_envelope = pd.DataFrame(\n",
    "            resampled_mfd_envelope, columns=['flow', 'occupancy'])\n",
    "\n",
    "        # calculate the 95th/ 97.5th percentile of flow as the capacity\n",
    "        capacity = np.percentile(\n",
    "            resampled_mfd_envelope.flow, 97.5, method='nearest')\n",
    "\n",
    "        rounded_capacity = round(capacity, 2)\n",
    "\n",
    "        matching_rows = resampled_mfd_envelope.loc[round(\n",
    "            resampled_mfd_envelope.flow, 2) == rounded_capacity]\n",
    "        if not matching_rows.empty:\n",
    "            critical_occupancy = matching_rows['occupancy'].iloc[0]\n",
    "        else:\n",
    "            # Handle the case where no rows match the condition\n",
    "            # You might want to set a default value or raise an exception\n",
    "            critical_occupancy = None  # or any other suitable value\n",
    "\n",
    "        return resampled_mfd_envelope, capacity, critical_occupancy\n",
    "\n",
    "\n",
    "def get_ldd_for_district(district_list: list, gdf_ldd: gpd.GeoDataFrame):\n",
    "    districts = merge_districts(district_list)\n",
    "    ldd_within_districts = gpd.sjoin(\n",
    "        gdf_ldd, districts, how=\"inner\", op=\"within\")\n",
    "    ldd_within_districts.drop(columns=['index_right'], inplace=True)\n",
    "    ldd_within_districts = ldd_within_districts.groupby([\"iu_ac\", \"day\"]).filter(\n",
    "        lambda x: len(x) == 18 and x[\"q\"].notnull().all() and x[\"k\"].notnull().all())\n",
    "    ldd_within_districts.reset_index(drop=True, inplace=True)\n",
    "    return ldd_within_districts\n",
    "\n",
    "\n",
    "def filter_outliers(df, column_name):\n",
    "    # Calculate the first and third quartiles\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "\n",
    "    # Calculate the IQR\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 8 * IQR\n",
    "    upper_bound = Q3 + 8 * IQR\n",
    "\n",
    "    # Filter the data\n",
    "    filtered_df = df[(df[column_name] >= lower_bound) &\n",
    "                     (df[column_name] <= upper_bound)]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_parallel(linestring1, linestring2):\n",
    "    x1, y1 = linestring1.xy\n",
    "    x2, y2 = linestring2.xy\n",
    "    if abs(x2[-1] - x2[0]) < 1e-6 or abs(x1[-1] - x1[0]) < 1e-6:\n",
    "        return True\n",
    "    slope1 = (y1[-1] - y1[0]) / (x1[-1] - x1[0])\n",
    "    slope2 = (y2[-1] - y2[0]) / (x2[-1] - x2[0])\n",
    "    return abs(slope1 - slope2) < 0.2\n",
    "\n",
    "def get_road_network_graph(polygon):\n",
    "    ox.settings.log_console = True\n",
    "    G_road_network = ox.graph_from_polygon(\n",
    "        polygon, simplify=True, network_type=\"drive\")\n",
    "    nodes, edges = momepy.nx_to_gdf(G_road_network, points=True, lines=True)\n",
    "    edges['index'] = range(1, len(edges) + 1)\n",
    "    return nodes, edges\n",
    "\n",
    "def process_car_detectors(polygon):\n",
    "    df_car_detectors_without_multiples = df_car_detectors.drop_duplicates(\n",
    "        subset='iu_ac', keep='first')\n",
    "    boundary_gdf = gpd.GeoDataFrame(\n",
    "        geometry=[polygon], crs=df_car_detectors_without_multiples.crs)\n",
    "    car_detectors_within_boundary = gpd.sjoin(\n",
    "        df_car_detectors_without_multiples, boundary_gdf, op='within')\n",
    "    return car_detectors_within_boundary\n",
    "\n",
    "def get_merged_geodataframe(matched_detectors, ldd):\n",
    "    matched_detectors_without_dupl = matched_detectors.drop_duplicates(\n",
    "        subset='iu_ac', keep='first')\n",
    "    merged_ldd = pd.merge(ldd, matched_detectors_without_dupl[[\n",
    "                      'iu_ac', 'geometry_detector', 'highway', 'oneway', 'length_mapped_osm_street','score','length_detector_street','lanes_mapped']], on='iu_ac', how='inner')\n",
    "    merged_ldd['geometry_detector'] = merged_ldd['geometry_detector'].apply(loads)\n",
    "    return gpd.GeoDataFrame(merged_ldd, geometry='geometry_detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "car_detectors = process_car_detectors(polygon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinguished in primary and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldd_2010, ldd_2022 = read_detector_data()\n",
    "\n",
    "gdf_ldd_2010 = get_merged_geodataframe(matched_detectors_2013, ldd_2010)\n",
    "gdf_ldd_2022 = get_merged_geodataframe(matched_detectors_2022, ldd_2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gdf_merged_ldd sind weniger Einträge als in ldd. Es ist also anzunehmen, dass manche Detektoren, für die zwar gemessen wurde, nicht in dem eigentlichen Ding drin sind. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MFDs\n",
    "\n",
    "Zuerst erstellen wir die resampled MFDs. Zunächst für ldd_district_1_4_2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mfds_for_district(district: str, mfd_2010: ResampledMFD, mfd_2022: ResampledMFD, p_sample, n_combinations):\n",
    "    fig, ax = plt.subplots()\n",
    "    # plt.gcf().set_size_inches(4, 3) \n",
    "    plt.scatter(mfd_2010.resampled_mfd['occupancy'],\n",
    "                mfd_2010.resampled_mfd['flow'], s=0.5, color='grey', label='resampled MFD 2010')\n",
    "    plt.hlines(y=mfd_2010.capacity, xmin=0, xmax=mfd_2010.critical_occupancy, color='orange',\n",
    "               linestyle='-')\n",
    "    plt.vlines(x=mfd_2010.critical_occupancy, ymin=0, ymax=mfd_2010.capacity, color='orange',\n",
    "               linestyle='-')\n",
    "    plt.scatter(mfd_2010.resampled_mfd_envelope['occupancy'], mfd_2010.resampled_mfd_envelope['flow'],\n",
    "                marker='s', s=10, color='orange', label='MFD envelope 2010')\n",
    "\n",
    "    plt.scatter(mfd_2022.resampled_mfd['occupancy'],\n",
    "                mfd_2022.resampled_mfd['flow'], s=0.5, color='darkgrey', label='resampled MFD 2022')\n",
    "    plt.hlines(y=mfd_2022.capacity, xmin=0, xmax=mfd_2022.critical_occupancy, color='blue',\n",
    "               linestyle='-')\n",
    "    plt.vlines(x=mfd_2022.critical_occupancy, ymin=0, ymax=mfd_2022.capacity, color='blue',\n",
    "               linestyle='-')\n",
    "    plt.scatter(mfd_2022.resampled_mfd_envelope['occupancy'], mfd_2022.resampled_mfd_envelope['flow'],\n",
    "                marker='s', s=10, color='blue', label='MFD envelope 2022')\n",
    "\n",
    "    # if district == str([1, 2, 3, 4]):\n",
    "    #     plt.xlim(0, 90)\n",
    "    #     plt.ylim(0, 7500)\n",
    "    # elif district == str([5, 6, 7]):\n",
    "    #     plt.xlim(0, 100)\n",
    "    #     plt.ylim(0, 7000)\n",
    "    plt.xlabel('Density [veh/lane-km]')\n",
    "    plt.ylabel('Flow [veh/lane-km/h]')\n",
    "    plt.title('Resampled MFD (lane km) for districts ' + district+ \"_\" + str(p_sample) + \"_\" + str(n_combinations) + ' in 2010 and 2022')\n",
    "   \n",
    "    plt.legend()\n",
    "    plt.savefig(resultpath + 'resampled_mfd_per_lane_km_district_' + district + \"_\" +\n",
    "                str(p_sample) + \"_\" + str(n_combinations) + \".pdf\", dpi=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 2, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_38143/3592492084.py:143: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  ldd_within_districts = gpd.sjoin(\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_38143/3592492084.py:143: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  ldd_within_districts = gpd.sjoin(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474192 351774\n",
      "1 [5, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_38143/3592492084.py:143: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  ldd_within_districts = gpd.sjoin(\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_38143/3592492084.py:143: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  ldd_within_districts = gpd.sjoin(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657666 533898\n"
     ]
    }
   ],
   "source": [
    "# districts_to_test = [[1, 2, 3, 4], [5, 6, 7], [1, 2, 3], [5, 6], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "districts_to_test = [[1, 2, 3, 4], [5, 6, 7]]\n",
    "\n",
    "for idx, district in enumerate(districts_to_test):\n",
    "    print(idx, district)\n",
    "    ldd_district_2010 = get_ldd_for_district(district, gdf_ldd_2010)\n",
    "    ldd_district_2022 = get_ldd_for_district(district, gdf_ldd_2022)\n",
    "\n",
    "    # Map values to respective lane km\n",
    "    ldd_district_2010['q_per_lane_km'] = ldd_district_2010['q'] * 1000 / (ldd_district_2010['length_detector_street'] * ldd_district_2010['lanes_mapped'])\n",
    "    ldd_district_2010['k_per_lane_km'] = ldd_district_2010['k'] * 1000 / (ldd_district_2010['length_detector_street'] * ldd_district_2010['lanes_mapped'])\n",
    "\n",
    "    ldd_district_2022['q_per_lane_km'] = ldd_district_2022['q'] * 1000 / (ldd_district_2022['length_detector_street'] * ldd_district_2022['lanes_mapped'])\n",
    "    ldd_district_2022['k_per_lane_km'] = ldd_district_2022['k'] * 1000 / (ldd_district_2022['length_detector_street'] * ldd_district_2022['lanes_mapped'])\n",
    "\n",
    "    print(len(ldd_district_2010), len(ldd_district_2022))\n",
    "    continue\n",
    "\n",
    "    # # Filter for outliers\n",
    "    if district == [1, 2, 3, 4]:\n",
    "        ldd_district_2010 = ldd_district_2010[ldd_district_2010['k_per_lane_km'] < 180]\n",
    "        ldd_district_2022 = ldd_district_2022[ldd_district_2022['k_per_lane_km'] < 180]\n",
    "    # elif district == [5, 6, 7]:\n",
    "    #     ldd_district_2010 = ldd_district_2010[ldd_district_2010['k_per_lane_km'] < 100]\n",
    "    #     ldd_district_2022 = ldd_district_2022[ldd_district_2022['k_per_lane_km'] < 100]\n",
    "    # else:\n",
    "    #     print(\"NOT OK\")\n",
    "\n",
    "    resampled_district_2010 = ResampledMFD(ldd_district_2010, 0.6, 300)\n",
    "    resampled_district_2010.compute_resampled_mfd()\n",
    "    resampled_district_2010.print_resampled_mfd()\n",
    "\n",
    "    resampled_district_2022 = ResampledMFD(ldd_district_2022, 0.6, 300)\n",
    "    resampled_district_2022.compute_resampled_mfd()\n",
    "    resampled_district_2022.print_resampled_mfd()\n",
    "\n",
    "    plot_mfds_for_district(str(district), resampled_district_2010,\n",
    "                           resampled_district_2022, 0.6, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26344.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "474192/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
